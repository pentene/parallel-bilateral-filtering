<!DOCTYPE html>
<html>
<head>
    <title>Parallel Bilateral Filtering Implementation and Optimization</title>
</head>
<body>
    <h1>Parallel Bilateral Filtering Implementation and Optimization</h1>
    <h3>Team Members: [Your Name], [Partner's Name]</h3>

    <h2>URL</h2>
    <p>[Your Project URL Here (Github or Andrew UserWeb)]</p>

    <h2>Summary</h2>
    <p>
        We will implement optimized parallel versions of the bilateral filtering algorithm on CPU (OpenMP) and GPU (CUDA) platforms. We will benchmark and analyze the performance and scalability of different optimization strategies across both systems.
    </p>

    <h2>Background</h2>
    <p>
        Bilateral filtering is an image-processing algorithm designed for noise reduction while preserving edges by considering both spatial and intensity differences. Due to its computational complexity involving per-pixel operations within local neighborhoods, it can significantly benefit from parallel computing strategies. The independent calculation of each pixel provides substantial parallelism potential, ideal for acceleration using multi-core CPUs and GPUs.
    </p>

    <h2>The Challenge</h2>
    <p>
        The challenge lies in effectively parallelizing and optimizing memory access patterns, given bilateral filtering's inherent data-intensive nature. The algorithm requires intensive data access within each pixel's neighborhood, leading to challenges in memory bandwidth and cache performance on CPUs, and shared memory optimization and memory coalescing on GPUs. Ensuring minimal synchronization and efficient data-sharing among threads further complicates parallel implementation.
    </p>

    <h2>Resources</h2>
    <p>
        We will use standard lab machines with multi-core CPUs and CUDA-capable GPUs. The project starts from scratch, developing implementations using OpenMP for CPU parallelization and CUDA for GPU acceleration. Essential references include:
        <ul>
            <li>C. Tomasi and R. Manduchi, "Bilateral Filtering for Gray and Color Images," ICCV, 1998.</li>
            <li>NVIDIA CUDA Programming Guide</li>
        </ul>
    </p>

    <h2>Goals and Deliverables</h2>
    <h3>Plan to Achieve:</h3>
    <ul>
        <li>Sequential bilateral filtering baseline implementation.</li>
        <li>Parallel bilateral filtering with OpenMP, achieving measurable speedup (targeting ~4-8x on 8-core CPU).</li>
        <li>GPU implementation using CUDA with basic optimizations (targeting at least 10-20x improvement over sequential).</li>
        <li>Detailed benchmarking and comparative performance analysis between CPU and GPU versions.</li>
    </ul>
    <h3>Hope to Achieve (if time permits):</h3>
    <ul>
        <li>Advanced GPU optimizations (shared memory, coalescing), targeting additional 2-4x speedup.</li>
        <li>Analysis of scalability on higher-resolution images.</li>
    </ul>

    <h2>Platform Choice</h2>
    <p>
        CPU with OpenMP allows effective parallelization and rapid prototyping of image processing kernels, whereas GPUs using CUDA provide substantial parallel arithmetic capability ideal for computationally heavy bilateral filtering. The combination enables insightful comparative analysis.
    </p>

    <h2>Schedule (Tentative)</h2>
    <ul>
        <li><b>Week 1-2:</b> Sequential implementation and baseline benchmarking.</li>
        <li><b>Week 3:</b> Initial OpenMP implementation.</li>
        <li><b>Week 4:</b> CPU optimizations (cache-aware blocking, SIMD).</li>
        <li><b>Week 5:</b> Initial GPU implementation and profiling.</li>
        <li><b>Week 6:</b> GPU memory optimizations (shared memory).</li>
        <li><b>Week 7:</b> GPU advanced optimization (memory coalescing, occupancy tuning).</li>
        <li><b>Week 8:</b> Complete GPU optimization and extensive benchmarking.</li>
        <li><b>Week 9:</b> Comparative performance analysis.</li>
        <li><b>Week 10 (by April 15th milestone):</b> Documentation, report writing, and preparation for final presentation.</li>
    </ul>
</body>
</html>
